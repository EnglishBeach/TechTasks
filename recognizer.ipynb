{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1664f46aa10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real= cv2.imread(\n",
    "r\"D:\\WORKS\\TechTasks\\DocData\\2.jpg\"\n",
    ")\n",
    "plt.imshow(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_image(image: np.ndarray, max_size=2048)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Maxi size, defaults to 2048\n",
    "    :return: Downscaled image\n",
    "    \"\"\"\n",
    "    x, y = image.shape\n",
    "    max_dimention = max(x, y)\n",
    "\n",
    "    if max_dimention <= max_size:\n",
    "        return image\n",
    "\n",
    "    scale = max_size / max_dimention\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1664a716050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "img_gray = downscale_image(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find text boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rank_filter\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class BlockTuple(NamedTuple):\n",
    "    \"\"\"Tuple for masks on picture\"\"\"\n",
    "\n",
    "    i: int\n",
    "    \"\"\"Mask Order number\"\"\"\n",
    "\n",
    "    power: int\n",
    "    \"\"\"Nonzero pixels count Number \"\"\"\n",
    "\n",
    "    mask: np.ndarray\n",
    "    \"\"\"Space mask\"\"\"\n",
    "\n",
    "\n",
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x,y dx,dy\"\"\"\n",
    "\n",
    "    x: int\n",
    "    y: int\n",
    "    dx: int\n",
    "    dy: int\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    \"\"\"Attention area\"\"\"\n",
    "\n",
    "    border_scale = 0.05\n",
    "    \"\"\"Border thickness proporitonal image size\"\"\"\n",
    "\n",
    "    def __init__(self, attention_mask, image) -> None:\n",
    "        \"\"\"\n",
    "        Create attention area around attention_mask\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "        y_full, x_full = image.shape\n",
    "        y_border = int(y_full * self.border_scale)\n",
    "        x_border = int(x_full * self.border_scale)\n",
    "\n",
    "        non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "\n",
    "        window_slice = (\n",
    "            slice(y - y_border, y + dy + y_border),\n",
    "            slice(x - x_border, x + dx + x_border),\n",
    "        )\n",
    "        window = np.zeros_like(image)\n",
    "        window[window_slice] = image[window_slice]\n",
    "\n",
    "        self.attention_full = attention_mask\n",
    "        self.window_full = window\n",
    "\n",
    "        self.inside_box = BoxProperties(cv2.boundingRect(non_zero_coords))\n",
    "        self.outside_box = BoxProperties(\n",
    "            x - x_border,\n",
    "            y - y_border,\n",
    "            dx + 2 * x_border,\n",
    "            dy + 2 * y_border,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def attention_cropped(self):\n",
    "\n",
    "        (\n",
    "        slice(box.y - y_border, box.y + box.dy + y_border),\n",
    "        slice(box.x - x_border, box.x + box.dx + x_border),\n",
    "        )\n",
    "        window = np.zeros_like(image)\n",
    "        window[window_slice] = image[window_slice]\n",
    "\n",
    "        mask = np.zeros_like(self.attention_full)\n",
    "        mask\n",
    "        self.inside_box\n",
    "        return cv2.bitwise_and(self.attention_full, self.attention_full, mask=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def watch(attention_mask: np.ndarray, image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "#     \"\"\"\n",
    "#     Get attention area around attention_mask\n",
    "\n",
    "#     :param attention_mask: Used mask to look around\n",
    "#     :param image: Full image\n",
    "#     :return: Attention window and parametrs for it (what we see and where need to see)\n",
    "#     \"\"\"\n",
    "\n",
    "#     border_scale = 0.05\n",
    "#     y_full, x_full = image.shape\n",
    "#     y_border = int(y_full * border_scale)\n",
    "#     x_border = int(x_full * border_scale)\n",
    "#     box = Box(attention_mask)\n",
    "#     # x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "#     window_slice = (\n",
    "#         slice(box.y - y_border, box.y + box.dy + y_border),\n",
    "#         slice(box.x - x_border, box.x + box.dx + x_border),\n",
    "#     )\n",
    "#     window = np.zeros_like(image)\n",
    "#     window[window_slice] = image[window_slice]\n",
    "#     return window, box\n",
    "\n",
    "\n",
    "def get_F_metric(mask: np.ndarray, window: np.ndarray):\n",
    "    mask = mask.copy()\n",
    "    mask[mask != 0] = 1\n",
    "    window = window.copy()\n",
    "    window[window != 0] = 1\n",
    "\n",
    "    dy, dx = window.shape\n",
    "\n",
    "    tp = np.count_nonzero(mask)\n",
    "    fp = dx * dy\n",
    "    fn = np.count_nonzero(window - mask)\n",
    "    return 2 * tp / (2 * tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img_gray\n",
    "a = cv2.GaussianBlur(a, (5, 5), 5)\n",
    "a = cv2.Canny(a, 100, 200)\n",
    "a = rank_filter(a, rank=5, size=3)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "n_rectangles = 1000\n",
    "while n_rectangles > 20:\n",
    "    a = cv2.dilate(a, kernel, iterations=1)\n",
    "    n_rectangles, block_map = cv2.connectedComponents(a)\n",
    "    n_rectangles -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranged_blocks: list[BlockTuple] = sorted(\n",
    "    [\n",
    "        BlockTuple(\n",
    "            i,\n",
    "            np.count_nonzero((block_map == i) * 1),\n",
    "            np.uint8(block_map == i),\n",
    "        )\n",
    "        for i in range(1, n_rectangles)\n",
    "    ],\n",
    "    key=lambda x: x.power,\n",
    ")\n",
    "print(n_rectangles - 1)\n",
    "# a = cv2.dilate(a, kernel, iterations=5)\n",
    "plt.imshow(block_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs =[]\n",
    "while len(ranged_blocks):\n",
    "    focused = ranged_blocks.pop().mask.copy()\n",
    "    window, size = watch(focused, block_map)\n",
    "    start_F1 = get_F_metric(focused, window, size)\n",
    "\n",
    "    watched_blocks = [block for block in ranged_blocks if block.i in set(np.unique(window))]\n",
    "\n",
    "    while len(watched_blocks):\n",
    "        add_block = watched_blocks.pop()\n",
    "        focused_new = focused + add_block.mask\n",
    "        window, size = watch(focused_new, block_map)\n",
    "        F1 = get_F_metric(focused_new, window, size)\n",
    "        if F1 >= start_F1 * 0.9:\n",
    "            start_F1 = F1\n",
    "            focused = focused_new\n",
    "            ranged_blocks.remove(add_block)\n",
    "    paragraphs.append(focused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(focused_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sum([paragraphs[i] * (i+1) for i in range(len(paragraphs))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(paragraphs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_area_rect(image):\n",
    "    non_zero_coords = cv2.findNonZero(image)\n",
    "    return cv2.minAreaRect(non_zero_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "# TODO: find deriv from generator\n",
    "def _hightlight_text(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "\n",
    "    return _open_transform(image, best_kernel_size)\n",
    "\n",
    "\n",
    "scale = 1\n",
    "img = paragraphs[0]\n",
    "\n",
    "# non_zero_coords = cv2.findNonZero(_hightlight_text(img))\n",
    "# box = cv2.minAreaRect(non_zero_coords)\n",
    "# angle = box[2]\n",
    "\n",
    "# h, w = gray_image.shape\n",
    "# center = (w / 2, h / 2)\n",
    "# # FIXME: check another rotations\n",
    "# rotate_M = cv2.getRotationMatrix2D(center, 45 - np.abs(np.abs(angle) - 45), scale)\n",
    "# aligned_image = cv2.warpAffine(\n",
    "#     gray_image.copy(), rotate_M, (w, h), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE\n",
    "# )\n",
    "\n",
    "# plt.imshow(aligned_image)\n",
    "\n",
    "# x, y, dx, dy = cv2.boundingRect(cv2.findNonZero(img))\n",
    "# plt.imshow(img[y:y+dy,x:x+dx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "mask2 = cv2.dilate(img, kernel, iterations=5)\n",
    "img2 = cv2.bitwise_and(img_gray, img_gray, mask=mask2)\n",
    "plt.imshow(img2)\n",
    "# plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(lang_list=['ru'],gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.readtext(img2, width_ths=0.7,height_ths=0.7,rotation_info =list(range(0,270)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
