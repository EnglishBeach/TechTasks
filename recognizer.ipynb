{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import rank_filter\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x190000b4be0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real = cv2.imread(r\"D:\\WORKS\\TechTasks\\DocData\\1.jpg\")\n",
    "plt.imshow(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(image: np.ndarray, max_size=1080)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Maxi size, defaults to 2048\n",
    "    :return: Downscaled image\n",
    "    \"\"\"\n",
    "\n",
    "    # if max_dimention <= max_size:\n",
    "    #     return image\n",
    "\n",
    "    scale = max_size / max(image.shape)\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19065d94c40>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "img_gray = cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "img_gray = rescale_image(img_gray)\n",
    "\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y,x = img_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 1920\n",
    "max_dimention = max(y,x)\n",
    "scale = max_size / max_dimention\n",
    "\n",
    "a = cv2.resize(\n",
    "        img_gray,\n",
    "        None,\n",
    "        dsize=(x*scale,y*scale),\n",
    "        interpolation=cv2.INTER_CUBIC\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x,y x1,y1\"\"\"\n",
    "\n",
    "    x0: int\n",
    "    y0: int\n",
    "    x1: int\n",
    "    y1: int\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    \"\"\"Find another blocks around attention area\"\"\"\n",
    "\n",
    "    border_scale = 0.05\n",
    "    \"\"\"Border thickness proporitonal image size\"\"\"\n",
    "\n",
    "    def __init__(self, attention_mask: np.ndarray, image: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Create attention area around attention_mask\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "\n",
    "        non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "        self.focus_box = BoxProperties(x, y, x + dx + 1, y + dy + 1)\n",
    "\n",
    "        y_full, x_full = image.shape\n",
    "        y_border = int(y_full * self.border_scale)\n",
    "        x_border = int(x_full * self.border_scale)\n",
    "        self.window_box = BoxProperties(\n",
    "            np.maximum(x - x_border, 0),\n",
    "            np.maximum(y - y_border, 0),\n",
    "            x + dx + 2 * x_border + 1,\n",
    "            y + dy + 2 * y_border + 1,\n",
    "        )\n",
    "\n",
    "        self.focus = attention_mask.copy()\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "        self.window = np.zeros_like(image)\n",
    "        self.window[window_slice] = image[window_slice].copy()\n",
    "\n",
    "    @property\n",
    "    def F1_metric(self) -> float:\n",
    "        \"\"\"F1 metric for a clasterisation quality\"\"\"\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "\n",
    "        focus = self.focus[window_slice].copy()\n",
    "        focus[focus != 0] = 1\n",
    "\n",
    "        window = self.window[window_slice].copy()\n",
    "        window[window != 0] = 1\n",
    "\n",
    "        dy, dx = focus.shape\n",
    "\n",
    "        tp = np.count_nonzero(focus)\n",
    "        fp = dx * dy\n",
    "        fn = np.count_nonzero(window - focus)\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    @property\n",
    "    def periphery_types(self):\n",
    "        return sorted(\n",
    "            set(np.unique(self.window)) - set(np.unique(self.focus)),\n",
    "            key=lambda i: np.count_nonzero(self.focus[self.focus == i] * 1),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def get_blocks_map(image: np.ndarray) -> tuple[dict[int, np.ndarray], list[int]]:\n",
    "    \"\"\"\n",
    "    Return separate text area masks on image\n",
    "\n",
    "    :param image: Image to analyse separate text blocks\n",
    "    :return: List of text area masks in the order of their power\n",
    "    \"\"\"\n",
    "    max_rectangles = 20\n",
    "\n",
    "    img = cv2.GaussianBlur(image, (3, 3), 5)\n",
    "    img = cv2.Canny(img, 100, 200)\n",
    "    img = rank_filter(img, rank=5, size=3)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    n_rectangles = max_rectangles + 1\n",
    "    while n_rectangles > max_rectangles:\n",
    "        img = cv2.dilate(img, kernel, iterations=1)\n",
    "        n_rectangles, segmented_img = cv2.connectedComponents(img)\n",
    "        n_rectangles -= 1\n",
    "\n",
    "    block_map = {i: np.uint8(segmented_img == i) * i for i in range(1, n_rectangles + 1)}\n",
    "\n",
    "    block_types = sorted(\n",
    "        list(range(1, n_rectangles + 1)),\n",
    "        key=lambda i: np.count_nonzero(block_map[i]),\n",
    "        reverse=True,\n",
    "    )\n",
    "    return block_map, block_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # img = cv2.GaussianBlur(img_gray, (3, 3), 5)\n",
    "# img = cv2.Canny(img, 100, 200)\n",
    "# img = rank_filter(img, rank=5, size=3)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1906069d6f0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(cv2.GaussianBlur(img_gray, (9, 9), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19060623880>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.GaussianBlur(img_gray, (9, 9), 2)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "open_image = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel, iterations=1)\n",
    "# plt.imshow(img)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "img = cv2.dilate(img, kernel, iterations=1)\n",
    "n_rectangles, segmented_img = cv2.connectedComponents(img)\n",
    "\n",
    "\n",
    "block_map = {i: np.uint8(segmented_img == i) * i for i in range(1, n_rectangles + 1)}\n",
    "\n",
    "not_used_block_types = sorted(\n",
    "    list(range(1, n_rectangles + 1)),\n",
    "    key=lambda i: np.count_nonzero(block_map[i]),\n",
    "    reverse=True,\n",
    ")\n",
    "img_block=sum(block_map.values())\n",
    "plt.imshow(img_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_map, not_used_block_types = get_blocks_map(img_gray)\n",
    "# img_block = sum(block_map.values())\n",
    "\n",
    "clasters = []\n",
    "while len(not_used_block_types):\n",
    "    central_i = not_used_block_types.pop(0)\n",
    "    area = AttentionArea(block_map[central_i], img_block)\n",
    "\n",
    "    claster_mask = area.focus.copy()\n",
    "    F1_metric = area.F1_metric\n",
    "\n",
    "    for periphery_type in [i for i in area.periphery_types if i in not_used_block_types]:\n",
    "        cv2.imshow(\n",
    "            'mask',\n",
    "            cv2.bitwise_not(np.sign(claster_mask) * 100 + np.sign(block_map[periphery_type]) * 20),\n",
    "        )\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        new_area = AttentionArea(claster_mask + block_map[periphery_type], img_block)\n",
    "        if new_area.F1_metric < F1_metric * 0.9:\n",
    "            continue\n",
    "        F1_metric = new_area.F1_metric\n",
    "        claster_mask += block_map[periphery_type]\n",
    "        not_used_block_types.remove(periphery_type)\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    # claster_mask = cv2.dilate(claster_mask, kernel, iterations=5)\n",
    "\n",
    "    clasters.append(np.sign(claster_mask) * (len(clasters) + 1))\n",
    "cv2.destroyAllWindows()\n",
    "# plt.imshow(img_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19060418850>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(sum(clasters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1906049cac0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = clasters[0]\n",
    "# plt.imshow(mask)\n",
    "img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=mask)\n",
    "plt.imshow(img_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "# TODO: find deriv from generator\n",
    "def _hightlight_text(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "\n",
    "    return _open_transform(image, best_kernel_size)\n",
    "\n",
    "\n",
    "scale = 1\n",
    "img = paragraphs[0]\n",
    "\n",
    "# non_zero_coords = cv2.findNonZero(_hightlight_text(img))\n",
    "# box = cv2.minAreaRect(non_zero_coords)\n",
    "# angle = box[2]\n",
    "\n",
    "# h, w = gray_image.shape\n",
    "# center = (w / 2, h / 2)\n",
    "# # FIXME: check another rotations\n",
    "# rotate_M = cv2.getRotationMatrix2D(center, 45 - np.abs(np.abs(angle) - 45), scale)\n",
    "# aligned_image = cv2.warpAffine(\n",
    "#     gray_image.copy(), rotate_M, (w, h), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE\n",
    "# )\n",
    "\n",
    "# plt.imshow(aligned_image)\n",
    "\n",
    "# x, y, dx, dy = cv2.boundingRect(cv2.findNonZero(img))\n",
    "# plt.imshow(img[y:y+dy,x:x+dx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img2)\n",
    "# plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(lang_list=['ru'],gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.readtext(img2, width_ths=0.7,height_ths=0.7,rotation_info =list(range(0,270)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
