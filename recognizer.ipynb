{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import rank_filter\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c42ab6f8d0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real = cv2.imread(r\"D:\\WORKS\\TechTasks\\DocData\\1.jpg\")\n",
    "y, x, _ = img_real.shape\n",
    "# rotate_M = cv2.getRotationMatrix2D((x / 2, y / 2), 10, 1)\n",
    "# img_real = cv2.warpAffine(img_real, rotate_M, (x, y), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE)\n",
    "\n",
    "plt.imshow(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image: np.ndarray):\n",
    "    dy, dx = image.shape[:2]\n",
    "    y_size = 960\n",
    "    size= (int(dx * y_size/dy), y_size)\n",
    "\n",
    "    cv2.imshow('contours', cv2.resize(image,size ))\n",
    "    cv2.resizeWindow('contours', *size)\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def rescale_image(image: np.ndarray, max_size=1080) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Maxi size, defaults to 2048\n",
    "    :return: Downscaled image\n",
    "    \"\"\"\n",
    "\n",
    "    if max_size <= max_size:\n",
    "        return image\n",
    "\n",
    "    scale = max_size / max(image.shape)\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def make_square(img):\n",
    "    y, x = img.shape[:2]\n",
    "    max_side = max(y, x)\n",
    "\n",
    "    dy = max_side - y\n",
    "    dx = max_side - x\n",
    "\n",
    "    top = dy // 2\n",
    "    bottom = dy - top\n",
    "    left = dx // 2\n",
    "    right = dx - left\n",
    "    return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c42afbca50>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "# img_gray = rescale_image(img_gray)\n",
    "border_add = 10\n",
    "img_gray = cv2.copyMakeBorder(\n",
    "    img_gray,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    cv2.BORDER_CONSTANT,\n",
    "    value=[0, 0, 0],\n",
    ")\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 22])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intp((25.5 , 45))//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  find borders\n",
    "\n",
    "\n",
    "\n",
    "# img_processed = cv2.GaussianBlur(img_gray, (11, 11), 5)\n",
    "img_processed = cv2.Canny(img_gray, 100, 200)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "img_processed = cv2.dilate(img_processed, kernel, iterations=2)\n",
    "img_processed = np.sign(img_processed)*100\n",
    "# img_processed = rank_filter(img_processed, rank=5, size=3)\n",
    "plt.imshow(img_processed)\n",
    "\n",
    "\n",
    "non_zero_coords = cv2.findNonZero(img_processed)\n",
    "x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "img_center = np.intp((x+dx , y+dy))//2\n",
    "n = 100\n",
    "a = dy / dx\n",
    "\n",
    "contours_info = []\n",
    "contours, _ = cv2.findContours(img_processed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for contour in contours:\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = np.intp(cv2.boxPoints(rect))\n",
    "    center = rect[0]\n",
    "    size = rect[1]\n",
    "\n",
    "    # border_metric = (a * (center[0]) - img_center[0]) ** n + (center[1] - img_center[1]) ** n\n",
    "    # border_metric **=1/n\n",
    "\n",
    "    border_metric = not 1/30<size[0]/size[1]<30\n",
    "\n",
    "    contours_info.append((box, border_metric))\n",
    "# TODO: quantil metric\n",
    "# max_metric = np.quantile([i[1] for i in contours_info],0.75)\n",
    "# border_contours = list(filter(lambda x: x[1] >= max_metric, contours_info))\n",
    "border_contours = list(filter(lambda x: x[1] , contours_info))\n",
    "\n",
    "\n",
    "img_show = img_processed.copy()\n",
    "for i in border_contours:\n",
    "    cv2.drawContours(img_show, i, 0, (255, 0, 0), 2)\n",
    "\n",
    "show(img_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c42f8fa490>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(sorted([i[1] for i in contours_info]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours0, hierarchy = cv2.findContours( img_processed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for contour in contours0:\n",
    "#     rect = cv2.minAreaRect(contour)\n",
    "#     box = np.intp(cv2.boxPoints(rect))\n",
    "\n",
    "#     cv2.drawContours(img_processed,[box],0,(255,0,0),2)\n",
    "\n",
    "#     cv2.imshow('contours', cv2.resize(img_processed,(760,760)))\n",
    "#     cv2.resizeWindow('contours', 760, 760)\n",
    "#     cv2.waitKey()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def align(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "    opened_image = _open_transform(image, best_kernel_size)\n",
    "\n",
    "    non_zero_coordinates = cv2.findNonZero(opened_image)\n",
    "    box = cv2.minAreaRect(non_zero_coordinates)\n",
    "    box_x, box_y =box[1]\n",
    "    angle = box[2]\n",
    "\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    if (angle >45) and box_x>box_y:\n",
    "        angle -=90\n",
    "\n",
    "    y, x = image.shape\n",
    "    rotate_M = cv2.getRotationMatrix2D((x / 2, y / 2), angle, 1)\n",
    "\n",
    "    boxPts = cv2.boxPoints(box)\n",
    "    imageCopy = image.copy()\n",
    "\n",
    "    return cv2.warpAffine(imageCopy, rotate_M, (x, y), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14831586e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray =align(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x,y x1,y1\"\"\"\n",
    "\n",
    "    x0: int\n",
    "    y0: int\n",
    "    x1: int\n",
    "    y1: int\n",
    "\n",
    "\n",
    "def get_mask_map(image: np.ndarray) -> tuple[dict[int, np.ndarray], list[int]]:\n",
    "    \"\"\"\n",
    "    Return separate text area masks on image\n",
    "\n",
    "    :param image: Image to analyse separate text blocks\n",
    "    :return: List of text area masks in the order of their power\n",
    "    \"\"\"\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    n_rectangles, segmented_img = cv2.connectedComponents(img)\n",
    "\n",
    "    types_map = {i: np.uint8(segmented_img == i) * i for i in range(1, n_rectangles + 1)}\n",
    "\n",
    "    type_list = sorted(\n",
    "        list(range(1, n_rectangles + 1)),\n",
    "        key=lambda i: np.count_nonzero(types_map[i]),\n",
    "        reverse=True,\n",
    "    )\n",
    "    return types_map, type_list\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    \"\"\"Find another blocks around attention area\"\"\"\n",
    "\n",
    "    border_scale = 0.02\n",
    "    \"\"\"Border thickness proporitonal image size\"\"\"\n",
    "\n",
    "    def __init__(self, attention_mask: np.ndarray, image: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Create attention area around attention_mask\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "\n",
    "        non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "        self.focus_box = BoxProperties(x, y, x + dx, y + dy)\n",
    "\n",
    "        y_full, x_full = image.shape\n",
    "        y_border = int(y_full * self.border_scale)\n",
    "        x_border = int(x_full * self.border_scale)\n",
    "        self.window_box = BoxProperties(\n",
    "            max(x - x_border, 0),\n",
    "            max(y - y_border, 0),\n",
    "            min(x + dx + x_border, x_full),\n",
    "            min(y + dy + y_border, y_full),\n",
    "        )\n",
    "\n",
    "        self.focus = attention_mask.copy()\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "        self.window = np.zeros_like(image)\n",
    "        self.window[window_slice] = image[window_slice].copy()\n",
    "\n",
    "    @property\n",
    "    def F1_metric(self) -> float:\n",
    "        \"\"\"F1 metric for a clasterisation quality\"\"\"\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "\n",
    "        focus = self.focus[window_slice].copy()\n",
    "        focus[focus != 0] = 1\n",
    "\n",
    "        window = self.window[window_slice].copy()\n",
    "        window[window != 0] = 1\n",
    "\n",
    "        dy, dx = focus.shape\n",
    "\n",
    "        tp = np.count_nonzero(focus)\n",
    "        fp = dx * dy\n",
    "        fn = np.count_nonzero(window - focus)\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    def get_periphery_types(self):\n",
    "        rule_func = lambda i: np.count_nonzero(\n",
    "            self.focus[self.focus == i] * 1,\n",
    "        ) + np.count_nonzero(\n",
    "            self.window[self.window == i] * 1,\n",
    "        )\n",
    "\n",
    "        return sorted(\n",
    "            set(np.unique(self.window)) - set(np.unique(self.focus)),\n",
    "            key=rule_func,\n",
    "            reverse=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14830d244d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_processed = cv2.GaussianBlur(img_gray, (3, 3), 5)\n",
    "img_processed = cv2.Canny(img_processed, 100, 200)\n",
    "# img_processed = rank_filter(img_processed, rank=5, size=3)\n",
    "plt.imshow(img_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14830d76ed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_map, mask_types = get_mask_map(img_processed)\n",
    "typed_mask = sum(mask_map.values())\n",
    "plt.imshow(typed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14836a76310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasters = []\n",
    "while len(mask_types):\n",
    "    central_type = mask_types.pop(0)\n",
    "    area = AttentionArea(mask_map[central_type], typed_mask)\n",
    "\n",
    "    periphery_types = area.get_periphery_types()\n",
    "\n",
    "    while len(periphery_types):\n",
    "        periphery_type = periphery_types.pop(0)\n",
    "        new_area = AttentionArea(area.focus + mask_map[periphery_type], typed_mask)\n",
    "\n",
    "        # add_img = sum([types_map[i] for i in area.get_periphery_types()])\n",
    "        # show_img = cv2.bitwise_not(\n",
    "        #     np.sign(area.focus) * 200\n",
    "        #     + np.sign(types_map[periphery_type]) * 50\n",
    "        #     + np.sign(add_img) * 15\n",
    "        # )\n",
    "        # cv2.rectangle(\n",
    "        #     show_img,\n",
    "        #     (area.window_box.x0, area.window_box.y0),\n",
    "        #     (area.window_box.x1, area.window_box.y1),\n",
    "        #     200,\n",
    "        # )\n",
    "        # cv2.rectangle(\n",
    "        #     show_img,\n",
    "        #     (area.focus_box.x0, area.focus_box.y0),\n",
    "        #     (area.focus_box.x1, area.focus_box.y1),\n",
    "        #     200,\n",
    "        # )\n",
    "        # cv2.imshow('m', show_img)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        if (new_area.F1_metric < area.F1_metric * 0.9) or (periphery_type not in mask_types):\n",
    "            continue\n",
    "\n",
    "        area = new_area\n",
    "        periphery_types = area.get_periphery_types()\n",
    "        mask_types.remove(periphery_type)\n",
    "\n",
    "    claster = np.sign(area.focus) * (len(clasters) + 1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    claster = cv2.dilate(claster, kernel, iterations=5)\n",
    "    clasters.append(claster)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# plt.imshow(img_block)\n",
    "\n",
    "plt.imshow(sum(clasters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14836a3fd90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask = clasters[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(mask)\n",
    "img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=img_mask)\n",
    "non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "plt.imshow(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(img_cropped,lang='rus+eng',config='--psm 3')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyaspeller import YandexSpeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Благодарственное письмо-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speller = YandexSpeller()\n",
    "print(speller.spelled(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "# TODO: find deriv from generator\n",
    "def _hightlight_text(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "\n",
    "    return _open_transform(image, best_kernel_size)\n",
    "\n",
    "\n",
    "scale = 1\n",
    "img = paragraphs[0]\n",
    "\n",
    "# non_zero_coords = cv2.findNonZero(_hightlight_text(img))\n",
    "# box = cv2.minAreaRect(non_zero_coords)\n",
    "# angle = box[2]\n",
    "\n",
    "# h, w = gray_image.shape\n",
    "# center = (w / 2, h / 2)\n",
    "# # FIXME: check another rotations\n",
    "# rotate_M = cv2.getRotationMatrix2D(center, 45 - np.abs(np.abs(angle) - 45), scale)\n",
    "# aligned_image = cv2.warpAffine(\n",
    "#     gray_image.copy(), rotate_M, (w, h), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE\n",
    "# )\n",
    "\n",
    "# plt.imshow(aligned_image)\n",
    "\n",
    "# x, y, dx, dy = cv2.boundingRect(cv2.findNonZero(img))\n",
    "# plt.imshow(img[y:y+dy,x:x+dx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img2)\n",
    "# plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
