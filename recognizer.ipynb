{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import rank_filter\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21822f2f610>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_real = cv2.imread(r\"D:\\WORKS\\TechTasks\\DocData\\3.jpg\")\n",
    "y, x, _ = img_real.shape\n",
    "# rotate_M = cv2.getRotationMatrix2D((x / 2, y / 2), 10, 1)\n",
    "# img_real = cv2.warpAffine(img_real, rotate_M, (x, y), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE)\n",
    "\n",
    "plt.imshow(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_image(image: np.ndarray, max_size=1080)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Maxi size, defaults to 2048\n",
    "    :return: Downscaled image\n",
    "    \"\"\"\n",
    "\n",
    "    if max_size <= max_size:\n",
    "        return image\n",
    "\n",
    "    scale = max_size / max(image.shape)\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def make_square(img):\n",
    "    border_add = 10\n",
    "    y, x = img.shape[:2]\n",
    "    max_side = max(y, x)\n",
    "\n",
    "    dy = max_side - y\n",
    "    dx = max_side - x\n",
    "\n",
    "    top = dy // 2 + border_add\n",
    "    bottom = dy - top + border_add * 2\n",
    "    left = dx // 2 + border_add\n",
    "    right = dx - left + border_add * 2\n",
    "    return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2182085f730>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "img_gray = rescale_image(img_gray)\n",
    "img_gray= make_square(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21822b7c8e0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_processed = cv2.GaussianBlur(img_gray, (11, 11), 5)\n",
    "# img_processed = cv2.Canny(img_processed, 100, 200)\n",
    "# img_processed = rank_filter(img_processed, rank=5, size=3)\n",
    "plt.imshow(img_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours0, hierarchy = cv2.findContours( img_processed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours0:\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.intp(box)\n",
    "    cv2.drawContours(img_processed,[box],0,(255,0,0),2)\n",
    "\n",
    "    cv2.imshow('contours', cv2.resize(img_processed,(760,760)))\n",
    "    cv2.resizeWindow('contours', 760, 760)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1, -1, -1, -1],\n",
       "        [ 2,  0, -1, -1],\n",
       "        [ 3,  1, -1, -1],\n",
       "        [ 4,  2, -1, -1],\n",
       "        [ 5,  3, -1, -1],\n",
       "        [ 6,  4, -1, -1],\n",
       "        [ 7,  5, -1, -1],\n",
       "        [ 8,  6, -1, -1],\n",
       "        [ 9,  7, -1, -1],\n",
       "        [10,  8, -1, -1],\n",
       "        [11,  9, -1, -1],\n",
       "        [12, 10, -1, -1],\n",
       "        [13, 11, -1, -1],\n",
       "        [14, 12, -1, -1],\n",
       "        [15, 13, -1, -1],\n",
       "        [16, 14, -1, -1],\n",
       "        [17, 15, -1, -1],\n",
       "        [18, 16, -1, -1],\n",
       "        [19, 17, -1, -1],\n",
       "        [20, 18, -1, -1],\n",
       "        [21, 19, -1, -1],\n",
       "        [22, 20, -1, -1],\n",
       "        [23, 21, -1, -1],\n",
       "        [24, 22, -1, -1],\n",
       "        [25, 23, -1, -1],\n",
       "        [26, 24, -1, -1],\n",
       "        [27, 25, -1, -1],\n",
       "        [28, 26, -1, -1],\n",
       "        [29, 27, -1, -1],\n",
       "        [30, 28, -1, -1],\n",
       "        [31, 29, -1, -1],\n",
       "        [32, 30, -1, -1],\n",
       "        [33, 31, -1, -1],\n",
       "        [34, 32, -1, -1],\n",
       "        [35, 33, -1, -1],\n",
       "        [36, 34, -1, -1],\n",
       "        [37, 35, -1, -1],\n",
       "        [38, 36, -1, -1],\n",
       "        [39, 37, -1, -1],\n",
       "        [40, 38, -1, -1],\n",
       "        [41, 39, -1, -1],\n",
       "        [42, 40, -1, -1],\n",
       "        [43, 41, -1, -1],\n",
       "        [44, 42, -1, -1],\n",
       "        [45, 43, -1, -1],\n",
       "        [46, 44, -1, -1],\n",
       "        [47, 45, -1, -1],\n",
       "        [48, 46, -1, -1],\n",
       "        [49, 47, -1, -1],\n",
       "        [50, 48, -1, -1],\n",
       "        [51, 49, -1, -1],\n",
       "        [52, 50, -1, -1],\n",
       "        [53, 51, -1, -1],\n",
       "        [54, 52, -1, -1],\n",
       "        [55, 53, -1, -1],\n",
       "        [56, 54, -1, -1],\n",
       "        [57, 55, -1, -1],\n",
       "        [58, 56, -1, -1],\n",
       "        [59, 57, -1, -1],\n",
       "        [60, 58, -1, -1],\n",
       "        [61, 59, -1, -1],\n",
       "        [62, 60, -1, -1],\n",
       "        [63, 61, -1, -1],\n",
       "        [64, 62, -1, -1],\n",
       "        [65, 63, -1, -1],\n",
       "        [66, 64, -1, -1],\n",
       "        [67, 65, -1, -1],\n",
       "        [68, 66, -1, -1],\n",
       "        [69, 67, -1, -1],\n",
       "        [70, 68, -1, -1],\n",
       "        [71, 69, -1, -1],\n",
       "        [72, 70, -1, -1],\n",
       "        [73, 71, -1, -1],\n",
       "        [74, 72, -1, -1],\n",
       "        [75, 73, -1, -1],\n",
       "        [76, 74, -1, -1],\n",
       "        [77, 75, -1, -1],\n",
       "        [78, 76, -1, -1],\n",
       "        [79, 77, -1, -1],\n",
       "        [80, 78, -1, -1],\n",
       "        [81, 79, -1, -1],\n",
       "        [82, 80, -1, -1],\n",
       "        [83, 81, -1, -1],\n",
       "        [84, 82, -1, -1],\n",
       "        [85, 83, -1, -1],\n",
       "        [86, 84, -1, -1],\n",
       "        [87, 85, -1, -1],\n",
       "        [88, 86, -1, -1],\n",
       "        [89, 87, -1, -1],\n",
       "        [90, 88, -1, -1],\n",
       "        [91, 89, -1, -1],\n",
       "        [92, 90, -1, -1],\n",
       "        [93, 91, -1, -1],\n",
       "        [94, 92, -1, -1],\n",
       "        [-1, 93, -1, -1]]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def align(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "    opened_image = _open_transform(image, best_kernel_size)\n",
    "\n",
    "    non_zero_coordinates = cv2.findNonZero(opened_image)\n",
    "    box = cv2.minAreaRect(non_zero_coordinates)\n",
    "    box_x, box_y =box[1]\n",
    "    angle = box[2]\n",
    "\n",
    "    if angle < -45:\n",
    "        angle += 90\n",
    "    if (angle >45) and box_x>box_y:\n",
    "        angle -=90\n",
    "\n",
    "    y, x = image.shape\n",
    "    rotate_M = cv2.getRotationMatrix2D((x / 2, y / 2), angle, 1)\n",
    "\n",
    "    boxPts = cv2.boxPoints(box)\n",
    "    imageCopy = image.copy()\n",
    "\n",
    "    return cv2.warpAffine(imageCopy, rotate_M, (x, y), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c688a5660>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray =align(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x,y x1,y1\"\"\"\n",
    "\n",
    "    x0: int\n",
    "    y0: int\n",
    "    x1: int\n",
    "    y1: int\n",
    "\n",
    "\n",
    "def get_mask_map(image: np.ndarray) -> tuple[dict[int, np.ndarray], list[int]]:\n",
    "    \"\"\"\n",
    "    Return separate text area masks on image\n",
    "\n",
    "    :param image: Image to analyse separate text blocks\n",
    "    :return: List of text area masks in the order of their power\n",
    "    \"\"\"\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    n_rectangles, segmented_img = cv2.connectedComponents(img)\n",
    "\n",
    "    types_map = {i: np.uint8(segmented_img == i) * i for i in range(1, n_rectangles + 1)}\n",
    "\n",
    "    type_list = sorted(\n",
    "        list(range(1, n_rectangles + 1)),\n",
    "        key=lambda i: np.count_nonzero(types_map[i]),\n",
    "        reverse=True,\n",
    "    )\n",
    "    return types_map, type_list\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    \"\"\"Find another blocks around attention area\"\"\"\n",
    "\n",
    "    border_scale = 0.02\n",
    "    \"\"\"Border thickness proporitonal image size\"\"\"\n",
    "\n",
    "    def __init__(self, attention_mask: np.ndarray, image: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Create attention area around attention_mask\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "\n",
    "        non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "        self.focus_box = BoxProperties(x, y, x + dx, y + dy)\n",
    "\n",
    "        y_full, x_full = image.shape\n",
    "        y_border = int(y_full * self.border_scale)\n",
    "        x_border = int(x_full * self.border_scale)\n",
    "        self.window_box = BoxProperties(\n",
    "            max(x - x_border, 0),\n",
    "            max(y - y_border, 0),\n",
    "            min(x + dx + x_border, x_full),\n",
    "            min(y + dy + y_border, y_full),\n",
    "        )\n",
    "\n",
    "        self.focus = attention_mask.copy()\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "        self.window = np.zeros_like(image)\n",
    "        self.window[window_slice] = image[window_slice].copy()\n",
    "\n",
    "    @property\n",
    "    def F1_metric(self) -> float:\n",
    "        \"\"\"F1 metric for a clasterisation quality\"\"\"\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "\n",
    "        focus = self.focus[window_slice].copy()\n",
    "        focus[focus != 0] = 1\n",
    "\n",
    "        window = self.window[window_slice].copy()\n",
    "        window[window != 0] = 1\n",
    "\n",
    "        dy, dx = focus.shape\n",
    "\n",
    "        tp = np.count_nonzero(focus)\n",
    "        fp = dx * dy\n",
    "        fn = np.count_nonzero(window - focus)\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    def get_periphery_types(self):\n",
    "        rule_func = lambda i: np.count_nonzero(\n",
    "            self.focus[self.focus == i] * 1,\n",
    "        ) + np.count_nonzero(\n",
    "            self.window[self.window == i] * 1,\n",
    "        )\n",
    "\n",
    "        return sorted(\n",
    "            set(np.unique(self.window)) - set(np.unique(self.focus)),\n",
    "            key=rule_func,\n",
    "            reverse=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c7d9990c0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_processed = cv2.GaussianBlur(img_gray, (3, 3), 5)\n",
    "img_processed = cv2.Canny(img_processed, 100, 200)\n",
    "# img_processed = rank_filter(img_processed, rank=5, size=3)\n",
    "plt.imshow(img_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c76f85d50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_map, mask_types = get_mask_map(img_processed)\n",
    "typed_mask = sum(mask_map.values())\n",
    "plt.imshow(typed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c76fedab0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasters = []\n",
    "while len(mask_types):\n",
    "    central_type = mask_types.pop(0)\n",
    "    area = AttentionArea(mask_map[central_type], typed_mask)\n",
    "\n",
    "    periphery_types = area.get_periphery_types()\n",
    "\n",
    "    while len(periphery_types):\n",
    "        periphery_type = periphery_types.pop(0)\n",
    "        new_area = AttentionArea(area.focus + mask_map[periphery_type], typed_mask)\n",
    "\n",
    "        # add_img = sum([types_map[i] for i in area.get_periphery_types()])\n",
    "        # show_img = cv2.bitwise_not(\n",
    "        #     np.sign(area.focus) * 200\n",
    "        #     + np.sign(types_map[periphery_type]) * 50\n",
    "        #     + np.sign(add_img) * 15\n",
    "        # )\n",
    "        # cv2.rectangle(\n",
    "        #     show_img,\n",
    "        #     (area.window_box.x0, area.window_box.y0),\n",
    "        #     (area.window_box.x1, area.window_box.y1),\n",
    "        #     200,\n",
    "        # )\n",
    "        # cv2.rectangle(\n",
    "        #     show_img,\n",
    "        #     (area.focus_box.x0, area.focus_box.y0),\n",
    "        #     (area.focus_box.x1, area.focus_box.y1),\n",
    "        #     200,\n",
    "        # )\n",
    "        # cv2.imshow('m', show_img)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "        if (new_area.F1_metric < area.F1_metric * 0.9) or (periphery_type not in mask_types):\n",
    "            continue\n",
    "\n",
    "        area = new_area\n",
    "        periphery_types = area.get_periphery_types()\n",
    "        mask_types.remove(periphery_type)\n",
    "\n",
    "    claster = np.sign(area.focus) * (len(clasters) + 1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    claster = cv2.dilate(claster, kernel, iterations=5)\n",
    "    clasters.append(claster)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# plt.imshow(img_block)\n",
    "\n",
    "plt.imshow(sum(clasters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16c687745e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_mask = clasters[7]\n",
    "# plt.imshow(mask)\n",
    "img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=img_mask)\n",
    "plt.imshow(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(img_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(img_cropped,lang='rus+eng',config='--psm 3')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyaspeller import YandexSpeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Благодарственное письмо-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "speller = YandexSpeller()\n",
    "print(speller.spelled(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _open_transform(image, kernel_size):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    filtered_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "# TODO: find deriv from generator\n",
    "def _hightlight_text(image):\n",
    "    quality = np.array([np.count_nonzero(_open_transform(image, i)) for i in range(1, 10)])\n",
    "    d_quality = np.diff(quality)\n",
    "    best_kernel_size = np.where(d_quality == min(d_quality))[0][0] + 1\n",
    "\n",
    "    return _open_transform(image, best_kernel_size)\n",
    "\n",
    "\n",
    "scale = 1\n",
    "img = paragraphs[0]\n",
    "\n",
    "# non_zero_coords = cv2.findNonZero(_hightlight_text(img))\n",
    "# box = cv2.minAreaRect(non_zero_coords)\n",
    "# angle = box[2]\n",
    "\n",
    "# h, w = gray_image.shape\n",
    "# center = (w / 2, h / 2)\n",
    "# # FIXME: check another rotations\n",
    "# rotate_M = cv2.getRotationMatrix2D(center, 45 - np.abs(np.abs(angle) - 45), scale)\n",
    "# aligned_image = cv2.warpAffine(\n",
    "#     gray_image.copy(), rotate_M, (w, h), cv2.INTER_CUBIC, cv2.BORDER_REPLICATE\n",
    "# )\n",
    "\n",
    "# plt.imshow(aligned_image)\n",
    "\n",
    "# x, y, dx, dy = cv2.boundingRect(cv2.findNonZero(img))\n",
    "# plt.imshow(img[y:y+dy,x:x+dx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img2)\n",
    "# plt.imshow(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
