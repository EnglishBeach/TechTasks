{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real = cv2.imread(r\"D:\\WORKS\\TechTasks\\DocData\\2.jpg\")\n",
    "y, x, _ = img_real.shape\n",
    "plt.imshow(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image: np.ndarray):\n",
    "    dy, dx = image.shape[:2]\n",
    "    y_size = 960\n",
    "    size = (int(dx * y_size / dy), y_size)\n",
    "\n",
    "    cv2.imshow('contours', cv2.resize(image, size))\n",
    "    cv2.resizeWindow('contours', *size)\n",
    "\n",
    "    cv2.waitKey()\n",
    "\n",
    "\n",
    "def downscale_image(image: np.ndarray, max_size=2048) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Maxi size, defaults to 2048\n",
    "    :return: Downscaled image\n",
    "    \"\"\"\n",
    "\n",
    "    if max_size <= max_size:\n",
    "        return image\n",
    "\n",
    "    scale = max_size / max(image.shape)\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def make_square(image):\n",
    "    y, x = image.shape[:2]\n",
    "    max_side = max(y, x)\n",
    "\n",
    "    dy = max_side - y\n",
    "    dx = max_side - x\n",
    "\n",
    "    top = dy // 2\n",
    "    bottom = dy - top\n",
    "    left = dx // 2\n",
    "    right = dx - left\n",
    "    return cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "\n",
    "def align(image):\n",
    "    image_processed = cv2.Canny(image, 100, 200)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    image_processed = cv2.dilate(image_processed, kernel, iterations=2)\n",
    "    plt.imshow(image_processed)\n",
    "    non_zero_coordinates = cv2.findNonZero(image_processed)\n",
    "    box = cv2.minAreaRect(non_zero_coordinates)\n",
    "    (x, y), angle = box[1:]\n",
    "    if (-5 < angle < 5) or (90 - 5 < angle < 90 + 5) or (angle < -90 + 5):\n",
    "        return image\n",
    "\n",
    "    y, x = image.shape\n",
    "    rotate_M = cv2.getRotationMatrix2D((x // 2, y // 2), angle, 1)\n",
    "    return cv2.warpAffine(\n",
    "        image.copy(),\n",
    "        rotate_M,\n",
    "        (int(x), int(y)),\n",
    "        cv2.INTER_CUBIC,\n",
    "        cv2.BORDER_REPLICATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "img_gray = downscale_image(img_gray)\n",
    "border_add = 10\n",
    "img_gray = cv2.copyMakeBorder(\n",
    "    img_gray,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    cv2.BORDER_CONSTANT,\n",
    "    value=[0, 0, 0],\n",
    ")\n",
    "img_gray = make_square(img_gray)\n",
    "\n",
    "\n",
    "#  rotate_M = cv2.getRotationMatrix2D((x // 2, y // 2), angle, 1)\n",
    "#     cv2.warpAffine(\n",
    "#         image.copy(),\n",
    "#         rotate_M,\n",
    "#         (int(x), int(y)),\n",
    "#         cv2.INTER_CUBIC,\n",
    "#         cv2.BORDER_REPLICATE,\n",
    "#     )\n",
    "# img_gray = align(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x,y x1,y1\"\"\"\n",
    "\n",
    "    x0: int\n",
    "    y0: int\n",
    "    x1: int\n",
    "    y1: int\n",
    "\n",
    "\n",
    "def get_mask_map(image: np.ndarray) -> tuple[dict[int, np.ndarray], list[int]]:\n",
    "    \"\"\"\n",
    "    Return separate text area masks on image\n",
    "\n",
    "    :param image: Image to analyse separate text blocks\n",
    "    :return: List of text area masks in the order of their power\n",
    "    \"\"\"\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 2)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    n_rectangles, segmented_img = cv2.connectedComponents(img)\n",
    "\n",
    "    types_map = {i: np.uint8(segmented_img == i) * i for i in range(1, n_rectangles + 1)}\n",
    "\n",
    "    type_list = sorted(\n",
    "        list(range(1, n_rectangles + 1)),\n",
    "        key=lambda i: np.count_nonzero(types_map[i]),\n",
    "        reverse=True,\n",
    "    )\n",
    "    return types_map, type_list\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    \"\"\"Find another blocks around attention area\"\"\"\n",
    "\n",
    "    border_scale = 0.02\n",
    "    \"\"\"Border thickness proporitonal image size\"\"\"\n",
    "\n",
    "    def __init__(self, attention_mask: np.ndarray, image: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Create attention area around attention_mask\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "\n",
    "        non_zero_coords = cv2.findNonZero(attention_mask)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "        self.focus_box = BoxProperties(x, y, x + dx, y + dy)\n",
    "\n",
    "        y_full, x_full = image.shape\n",
    "        y_border = int(y_full * self.border_scale)\n",
    "        x_border = int(x_full * self.border_scale)\n",
    "        self.window_box = BoxProperties(\n",
    "            max(x - x_border, 0),\n",
    "            max(y - y_border, 0),\n",
    "            min(x + dx + x_border, x_full),\n",
    "            min(y + dy + y_border, y_full),\n",
    "        )\n",
    "\n",
    "        self.focus = attention_mask.copy()\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "        self.window = np.zeros_like(image)\n",
    "        self.window[window_slice] = image[window_slice].copy()\n",
    "\n",
    "    @property\n",
    "    def F1_metric(self) -> float:\n",
    "        \"\"\"F1 metric for a clasterisation quality\"\"\"\n",
    "        window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "\n",
    "        focus = self.focus[window_slice].copy()\n",
    "        focus[focus != 0] = 1\n",
    "\n",
    "        window = self.window[window_slice].copy()\n",
    "        window[window != 0] = 1\n",
    "\n",
    "        dy, dx = focus.shape\n",
    "\n",
    "        tp = np.count_nonzero(focus)\n",
    "        fp = dx * dy\n",
    "        fn = np.count_nonzero(window - focus)\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    def get_periphery_types(self):\n",
    "        rule_func = lambda i: np.count_nonzero(\n",
    "            self.focus[self.focus == i] * 1,\n",
    "        ) + np.count_nonzero(\n",
    "            self.window[self.window == i] * 1,\n",
    "        )\n",
    "\n",
    "        return sorted(\n",
    "            set(np.unique(self.window)) - set(np.unique(self.focus)),\n",
    "            key=rule_func,\n",
    "            reverse=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_processed = cv2.GaussianBlur(img_gray, (3, 3), 5)\n",
    "img_processed = cv2.Canny(img_processed, 100, 200)\n",
    "mask_map, mask_types = get_mask_map(img_processed)\n",
    "typed_mask = sum(mask_map.values())\n",
    "\n",
    "clasters = []\n",
    "while len(mask_types):\n",
    "    central_type = mask_types.pop(0)\n",
    "    area = AttentionArea(mask_map[central_type], typed_mask)\n",
    "\n",
    "    periphery_types = area.get_periphery_types()\n",
    "\n",
    "    while len(periphery_types):\n",
    "        periphery_type = periphery_types.pop(0)\n",
    "        new_area = AttentionArea(area.focus + mask_map[periphery_type], typed_mask)\n",
    "\n",
    "        add_img = sum([mask_map[i] for i in area.get_periphery_types()])\n",
    "        show_img = cv2.bitwise_not(\n",
    "            np.sign(area.focus) * 200\n",
    "            + np.sign(mask_map[periphery_type]) * 50\n",
    "            + np.sign(add_img) * 15\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            show_img,\n",
    "            (area.window_box.x0, area.window_box.y0),\n",
    "            (area.window_box.x1, area.window_box.y1),\n",
    "            200,\n",
    "            2,\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            show_img,\n",
    "            (area.focus_box.x0, area.focus_box.y0),\n",
    "            (area.focus_box.x1, area.focus_box.y1),\n",
    "            200,\n",
    "            2,\n",
    "        )\n",
    "        show(show_img)\n",
    "\n",
    "        if (new_area.F1_metric < area.F1_metric * 0.9) or (periphery_type not in mask_types):\n",
    "            continue\n",
    "\n",
    "        area = new_area\n",
    "        periphery_types = area.get_periphery_types()\n",
    "        mask_types.remove(periphery_type)\n",
    "\n",
    "    claster = np.sign(area.focus) * (len(clasters) + 1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    claster = cv2.dilate(claster, kernel, iterations=5)\n",
    "    clasters.append(claster)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.imshow(sum(clasters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sum(clasters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyaspeller import YandexSpeller\n",
    "# import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speller = YandexSpeller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clasters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.bitwise_and(img_gray, img_gray, mask=clasters[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognizeResult(NamedTuple):\n",
    "    text: str\n",
    "    angle: int\n",
    "    x: int\n",
    "    y: int\n",
    "    dx: int\n",
    "    dy: int\n",
    "\n",
    "\n",
    "res = []\n",
    "n = 0\n",
    "for img_mask in clasters:\n",
    "    n += 1\n",
    "\n",
    "    img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=img_mask)\n",
    "    non_zero_coords = cv2.findNonZero(img_mask)\n",
    "    box_cordinates = cv2.boundingRect(non_zero_coords)\n",
    "\n",
    "    # plt.imshow(img_cropped)\n",
    "\n",
    "    for angle in [0, -90, 90, 180]:\n",
    "        # text = pytesseract.image_to_string(img_cropped, lang='rus+eng', config='--psm 3')\n",
    "        # text = speller.spelled(text)\n",
    "        is_correct = angle == 180\n",
    "        text = str(n) + '\\n'\n",
    "        if len(text) and is_correct:\n",
    "            res.append(RecognizeResult(text, angle, *box_cordinates))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [i.angle for i in res]\n",
    "general_angle = max(set(angles), key=angles.count)\n",
    "slope = 2\n",
    "metric = {\n",
    "    0: lambda f: f. x + slope * f.y,\n",
    "    -90: lambda f: slope * f.x - (f.y + f.dy),\n",
    "    90: lambda f: -slope * (f.x + f.dx) + f.y,\n",
    "    180: lambda f: -(f.x + f.dx) - slope * (f.y + f.dy),\n",
    "}[general_angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([i.text for i in sorted(res, key=metric)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
