{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import NamedTuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pyaspeller import YandexSpeller\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "plt.rcParams['figure.subplot.left'] = 0.1\n",
    "plt.rcParams['figure.subplot.right'] = 0.99\n",
    "plt.rcParams['figure.subplot.top'] = 0.97\n",
    "plt.rcParams['figure.subplot.bottom'] = 0.05\n",
    "plt.rcParams['figure.subplot.hspace'] = 0.3\n",
    "matplotlib.rc(\"image\", cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare image\n",
    "Загрузка, подготовка изображения для распознавания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose tool for show image\n",
    "\n",
    "# Comment it if not use it\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "class ShowTool(Enum):\n",
    "    cv2= 'cv2'\n",
    "    plt='plt'\n",
    "\n",
    "SHOW_STYLE = ShowTool.plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "match SHOW_STYLE:\n",
    "    case ShowTool.plt:\n",
    "\n",
    "        def show(image: np.ndarray, y_size: int = 960):\n",
    "            \"\"\"\n",
    "            Show image in cv2 window\n",
    "\n",
    "            :param image: Image to show\n",
    "            :param y_size: Window scaler, defaults to 960\n",
    "            \"\"\"\n",
    "            plt.imshow(image)\n",
    "\n",
    "    case ShowTool.cv2:\n",
    "\n",
    "        def show(image: np.ndarray, y_size: int = 960):\n",
    "            \"\"\"\n",
    "            Show image in cv2 window\n",
    "\n",
    "            :param image: Image to show\n",
    "            :param y_size: Window scaler, defaults to 960\n",
    "            \"\"\"\n",
    "\n",
    "            dy, dx = image.shape[:2]\n",
    "            size = (int(dx * y_size / dy), y_size)\n",
    "\n",
    "            cv2.imshow('contours', cv2.resize(image, size))\n",
    "            cv2.resizeWindow('contours', *size)\n",
    "            cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Загружаем изображение и проверяем, правильное ли мы выбрали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_real = cv2.imread(r\"Data\\3.jpg\")\n",
    "y, x, _ = img_real.shape\n",
    "show(img_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align\n",
    "Выравниваем (насколько возможно) изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscale_image(image: np.ndarray, max_size: int = 1920) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Downscale image\n",
    "\n",
    "    :param image: Input image\n",
    "    :param max_size: Max size, defaults to 2048\n",
    "    :return: Downsized image\n",
    "    \"\"\"\n",
    "\n",
    "    # if max_size <= max_size:\n",
    "    #     return image\n",
    "\n",
    "    scale = max_size / max(image.shape)\n",
    "    return cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def make_square(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Make square from image to rotate it without a border cropping\n",
    "\n",
    "    :param image: Supplemented image to square\n",
    "    :return: Image\n",
    "    \"\"\"\n",
    "    y, x = image.shape[:2]\n",
    "    max_side = max(y, x)\n",
    "\n",
    "    dy = max_side - y\n",
    "    dx = max_side - x\n",
    "\n",
    "    top = dy // 2\n",
    "    bottom = dy - top\n",
    "    left = dx // 2\n",
    "    right = dx - left\n",
    "    return cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "\n",
    "def align(image: np.ndarray, tol: float = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Align image\n",
    "\n",
    "    :param image: Image to align\n",
    "    :param tol: Allowable angle deviation, defaults to 5\n",
    "    :return: Aligned image\n",
    "    \"\"\"\n",
    "    image_processed = cv2.Canny(image, 100, 200)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    image_processed = cv2.dilate(image_processed, kernel, iterations=2)\n",
    "\n",
    "    non_zero_coordinates = cv2.findNonZero(image_processed)\n",
    "    box = cv2.minAreaRect(non_zero_coordinates)\n",
    "    (x, y), angle = box[1:]\n",
    "\n",
    "    if (-tol < angle < tol) or (90 - tol < angle < 90 + tol) or (angle < -90 + tol):\n",
    "        return image\n",
    "\n",
    "    # FIXME: choose right\n",
    "    # y, x = image.shape\n",
    "    rotate_M = cv2.getRotationMatrix2D((x // 2, y // 2), angle, 1)\n",
    "    return cv2.warpAffine(\n",
    "        image.copy(),\n",
    "        rotate_M,\n",
    "        (int(x), int(y)),\n",
    "        cv2.INTER_CUBIC,\n",
    "        cv2.BORDER_REPLICATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img_real, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "img_gray = downscale_image(img_gray)\n",
    "\n",
    "# Add little borders to emphasize black spaces on borders\n",
    "border_add = 10\n",
    "img_gray = cv2.copyMakeBorder(\n",
    "    img_gray,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    border_add,\n",
    "    cv2.BORDER_CONSTANT,\n",
    "    value=[0, 0, 0],\n",
    ")\n",
    "img_gray = make_square(img_gray)\n",
    "show(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasterization\n",
    "Находим области с текстом о объединяем эти области в кластеры - абзацы для сохранения порядка слов при распознавания и исключения разрывов текста по середине абзаца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Mask`\n",
    "\n",
    "Находим границы объектов, чтобы не включать области у краев, шум и тд. Размываем изображение гауссовским ядром и применяем расширение для образования связанных блоков текста, формируя маску для каждого блока текста "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask:\n",
    "    def __init__(self, image: np.ndarray) -> None:\n",
    "        splitted_image = self._split(image)\n",
    "        n_rectangles, self.segmented_mask = cv2.connectedComponents(splitted_image)\n",
    "\n",
    "        self.map = {\n",
    "            i: np.uint8(self.segmented_mask == i) * i for i in range(1, n_rectangles + 1)\n",
    "        }\n",
    "        self.type_list = sorted(\n",
    "            list(range(1, n_rectangles + 1)),\n",
    "            key=lambda i: np.count_nonzero(self.map[i]),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _split(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Split image to connected blocks\n",
    "\n",
    "        :param image: Image to slit\n",
    "        :return: Mask with blocks\n",
    "        \"\"\"\n",
    "        bordered_image = cv2.Canny(image, 100, 200)\n",
    "        blur_kernel = (9, 9)\n",
    "        blur_image = cv2.GaussianBlur(bordered_image, blur_kernel, 2)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        dilate_image = cv2.dilate(blur_image, kernel, iterations=1)\n",
    "        return dilate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Mask(img_gray)\n",
    "show(mask.segmented_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В идеале нужно стремиться сохранить баланс между количеством несвязанных блоков и расстоянием между большими блоками. Для этого проводим кластеризацию блоков для выделения абзацев\n",
    "\n",
    "`AttentionArea`\n",
    "\n",
    "Обводим каждый такой блок текста (точнее его маску) прямоугольником - **фокус** и смотрим в небольшой области по краям - **область видимости** (её размеры определяются `window_border_scale`). Считаем F1 метрику на этой области. Находим блоки текста в других областях - **периферия**, сортируем в порядке возрастания числа пикселей.\n",
    "\n",
    "Добавляем новые области из периферии к фокусу так, чтобы метрика почти не уменьшалась (допуск уменьшения - `metric_tol`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxProperties(NamedTuple):\n",
    "    \"\"\"Box parameters: x0,y0 (left, top point) x1,y1 (right, bottom point)\"\"\"\n",
    "\n",
    "    x0: int\n",
    "    y0: int\n",
    "    x1: int\n",
    "    y1: int\n",
    "\n",
    "\n",
    "class AttentionArea:\n",
    "    window_border_scale = 0.02\n",
    "    \"\"\"Window border thickness proportional image size\"\"\"\n",
    "\n",
    "    def __init__(self, focus_image: np.ndarray, all_image: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Create box around focus image\n",
    "\n",
    "        :param attention_mask: Used mask to look around\n",
    "        :param image: Full image\n",
    "        \"\"\"\n",
    "        non_zero_coords = cv2.findNonZero(focus_image)\n",
    "        x, y, dx, dy = cv2.boundingRect(non_zero_coords)\n",
    "        self.focus_box = BoxProperties(x, y, x + dx, y + dy)\n",
    "\n",
    "        y_full, x_full = focus_image.shape\n",
    "        y_border = int(y_full * self.window_border_scale)\n",
    "        x_border = int(x_full * self.window_border_scale)\n",
    "        self.window_box = BoxProperties(\n",
    "            max(x - x_border, 0),\n",
    "            max(y - y_border, 0),\n",
    "            min(x + dx + x_border, x_full),\n",
    "            min(y + dy + y_border, y_full),\n",
    "        )\n",
    "        # self.image = all_image.copy()\n",
    "        self.window_slice = (\n",
    "            slice(self.window_box.y0, self.window_box.y1),\n",
    "            slice(self.window_box.x0, self.window_box.x1),\n",
    "        )\n",
    "        self.focus_slice = (\n",
    "            slice(self.focus_box.y0, self.focus_box.y1),\n",
    "            slice(self.focus_box.x0, self.focus_box.x1),\n",
    "        )\n",
    "\n",
    "        self.focus = focus_image.copy()\n",
    "        self.window = np.zeros_like(all_image)\n",
    "        self.window[self.window_slice] = all_image[self.window_slice].copy()\n",
    "\n",
    "    @property\n",
    "    def F1_metric(self) -> float:\n",
    "        \"\"\"F1 metric for a clusterization quality\"\"\"\n",
    "        dx, dy = self.focus_box.x1 - self.focus_box.x0, self.focus_box.y1 - self.focus_box.y0\n",
    "\n",
    "        tp = np.count_nonzero(self.focus)\n",
    "        fp = dx * dy - tp\n",
    "        fn = np.count_nonzero(np.sign(self.window) - np.sign(self.focus))\n",
    "        return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "    def get_periphery_types(self):\n",
    "        in_focus_box = self.window[self.focus_slice]\n",
    "        out_focus_box = self.window\n",
    "        periphery_types = []\n",
    "        for i in set(np.unique(self.window)) - set(np.unique(self.focus)):\n",
    "            power_in_focus_box = np.count_nonzero(\n",
    "                in_focus_box[in_focus_box == i] * 1,\n",
    "            )\n",
    "            power_in_window_box = np.count_nonzero(\n",
    "                out_focus_box[out_focus_box == i] * 1,\n",
    "            )\n",
    "            periphery_types.append((i, +power_in_window_box - power_in_focus_box))\n",
    "\n",
    "        return sorted(\n",
    "            periphery_types,\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # add_img = sum([mask.map[i] for i in area.get_periphery_types()])\n",
    "    # show_img = cv2.bitwise_not(\n",
    "    #     np.sign(area.focus) * 200\n",
    "    #     + np.sign(mask.map[periphery_type]) * 50\n",
    "    #     + np.sign(add_img) * 15\n",
    "    # )\n",
    "    # cv2.rectangle(\n",
    "    #     show_img,\n",
    "    #     (area.window_box.x0, area.window_box.y0),\n",
    "    #     (area.window_box.x1, area.window_box.y1),\n",
    "    #     200,\n",
    "    #     2,\n",
    "    # )\n",
    "    # cv2.rectangle(\n",
    "    #     show_img,\n",
    "    #     (area.focus_box.x0, area.focus_box.y0),\n",
    "    #     (area.focus_box.x1, area.focus_box.y1),\n",
    "    #     200,\n",
    "    #     2,\n",
    "    # )\n",
    "\n",
    "    # dy, dx = show_img.shape[:2]\n",
    "    # y_size = 960\n",
    "    # size = (int(dx * y_size / dy), y_size)\n",
    "\n",
    "    # cv2.imshow('contours', cv2.resize(show_img, size))\n",
    "    # cv2.resizeWindow('contours', *size)\n",
    "\n",
    "    # cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_list = mask.type_list.copy()\n",
    "\n",
    "central_type = types_list.pop(0)\n",
    "area = AttentionArea(mask.map[central_type], mask.segmented_mask)\n",
    "show(area.focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(area.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 210), (5, 637)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area.get_periphery_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(area.window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78  ->  0.78  :  210\n",
      "Bam\n",
      "\n",
      "0.78  ->  0.7  :  927\n",
      "\n",
      "0.7  ->  0.58  :  1005\n",
      "\n",
      "0.7  ->  0.54  :  3902\n",
      "\n",
      "0.66  ->  0.37  :  102\n",
      "\n",
      "0.33  ->  0.24  :  557\n",
      "\n",
      "0.33  ->  0.28  :  619\n",
      "\n",
      "0.33  ->  0.33  :  6416\n",
      "Bam\n",
      "\n",
      "0.33  ->  0.23  :  296\n",
      "\n",
      "0.33  ->  0.34  :  336\n",
      "Bam\n",
      "\n",
      "0.34  ->  0.23  :  296\n",
      "\n",
      "0.34  ->  0.3  :  687\n",
      "\n",
      "0.34  ->  0.29  :  1011\n",
      "\n",
      "0.34  ->  0.24  :  1542\n",
      "\n",
      "0.34  ->  0.32  :  2731\n",
      "Bam\n",
      "\n",
      "Inside\n",
      "0.33  ->  0.38  :  90\n",
      "Bam\n",
      "\n",
      "0.38  ->  0.29  :  221\n",
      "\n",
      "0.38  ->  0.29  :  462\n",
      "\n",
      "0.38  ->  0.31  :  1011\n",
      "\n",
      "0.38  ->  0.3  :  1215\n",
      "\n",
      "0.38  ->  0.35  :  2240\n",
      "\n",
      "0.38  ->  0.36  :  2898\n",
      "Bam\n",
      "\n",
      "0.36  ->  0.32  :  247\n",
      "\n",
      "0.36  ->  0.38  :  372\n",
      "Bam\n",
      "\n",
      "0.38  ->  0.29  :  462\n",
      "\n",
      "0.38  ->  0.34  :  641\n",
      "\n",
      "0.38  ->  0.31  :  1130\n",
      "\n",
      "0.38  ->  0.31  :  1154\n",
      "\n",
      "0.38  ->  0.36  :  1165\n",
      "Bam\n",
      "\n",
      "0.36  ->  0.33  :  641\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontours\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mresize(show_img, size))\n\u001b[0;32m     53\u001b[0m cv2\u001b[38;5;241m.\u001b[39mresizeWindow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontours\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39msize)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_area\u001b[38;5;241m.\u001b[39mF1_metric \u001b[38;5;241m>\u001b[39m area\u001b[38;5;241m.\u001b[39mF1_metric \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m metric_tol):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric_tol = 0.05\n",
    "types_list = mask.type_list.copy()\n",
    "\n",
    "# TODO: create rect around each mask and compare centers\n",
    "\n",
    "clusters = []\n",
    "\n",
    "while len(types_list):\n",
    "    central_type = types_list.pop(0)\n",
    "    area = AttentionArea(mask.map[central_type], mask.segmented_mask)\n",
    "\n",
    "    periphery_types = [i for i in area.get_periphery_types() if i[0] in types_list]\n",
    "    while len(periphery_types):\n",
    "        mask_type, key = periphery_types.pop(0)\n",
    "\n",
    "        if key == 0:\n",
    "            area.focus += mask.map[mask_type]\n",
    "            types_list.remove(mask_type)\n",
    "            print('Inside')\n",
    "            continue\n",
    "\n",
    "        new_area = AttentionArea(area.focus + mask.map[mask_type], mask.segmented_mask)\n",
    "\n",
    "        print(round(area.F1_metric, 2), ' -> ', round(new_area.F1_metric, 2), ' : ', key)\n",
    "\n",
    "        #\n",
    "        add_img = sum([mask.map[i] for i,_ in area.get_periphery_types()])\n",
    "        show_img = cv2.bitwise_not(\n",
    "            np.sign(area.focus) * 200\n",
    "            + np.sign(mask.map[mask_type]) * 50\n",
    "            + np.sign(add_img) * 15\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            show_img,\n",
    "            (area.window_box.x0, area.window_box.y0),\n",
    "            (area.window_box.x1, area.window_box.y1),\n",
    "            200,\n",
    "            2,\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            show_img,\n",
    "            (area.focus_box.x0, area.focus_box.y0),\n",
    "            (area.focus_box.x1, area.focus_box.y1),\n",
    "            200,\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        dy, dx = show_img.shape[:2]\n",
    "        y_size = 960\n",
    "        size = (int(dx * y_size / dy), y_size)\n",
    "\n",
    "        cv2.imshow('contours', cv2.resize(show_img, size))\n",
    "        cv2.resizeWindow('contours', *size)\n",
    "\n",
    "        cv2.waitKey()\n",
    "\n",
    "\n",
    "        if new_area.F1_metric > area.F1_metric * (1 - metric_tol):\n",
    "            print('Bam')\n",
    "            area = new_area\n",
    "            periphery_types = [i for i in area.get_periphery_types() if i[0] in types_list]\n",
    "            types_list.remove(mask_type)\n",
    "        print()\n",
    "\n",
    "    cluster = np.sign(area.focus) * (len(clusters) + 1)\n",
    "\n",
    "\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # cluster = cv2.dilate(cluster, kernel, iterations=5)\n",
    "    clusters.append(cluster)\n",
    "\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "plt.imshow(sum(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29282e86c50>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(sum(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize\n",
    "Распознаем текст на изображении и проверяем правильности написания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "speller = YandexSpeller()\n",
    "\n",
    "for cluster in clusters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= AttentionArea(segmented_mask=img_gray,focus_image=clusters[1])\n",
    "img_cropped = img_gray[a.focus_box.y0:a.focus_box.y1,a.focus_box.x0:a.focus_box.x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Строй Орнсте мы оформлялн сертификат 150 9001 для участия в\n",
      "тендере. Нас сразу привлекла стоямость в 19 тысяч рублей. И срочность:\n",
      "оформлекия сертификата, так как срохи у нас «горели». По телефону:\n",
      "получили грамотную консультецк по 15 и скан документа был у нас в\n",
      "ээтот же день. В результате тендер мы вынграли и успешно работзем.\n",
      "Спасибо СтройЮрнст, за качественную работу!\n",
      "\n",
      "**************************************************\n",
      "В Строй Орнсте мы оформляли сертификат 150 9001 для участия в\n",
      "тендере. Нас сразу привлекла стоимость в 19 тысяч рублей. И срочность:\n",
      "оформлекия сертификата, так как срохи у нас «горели». По телефону:\n",
      "получили грамотную консультацию по 15 и скан документа был у нас в\n",
      "этот же день. В результате тендер мы выиграли и успешно работаем.\n",
      "Спасибо Стройюрист, за качественную работу!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=clasters[1])\n",
    "plt.imshow(align(img_cropped),tol=)\n",
    "text = pytesseract.image_to_string(\n",
    "    align2(img_cropped),\n",
    "    lang='rus',\n",
    "    config='--psm 3',\n",
    ")\n",
    "print(text)\n",
    "print('*' * 50)\n",
    "print(speller.spelled(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognizeResult(NamedTuple):\n",
    "    text: str\n",
    "    angle: int\n",
    "    x: int\n",
    "    y: int\n",
    "    dx: int\n",
    "    dy: int\n",
    "\n",
    "\n",
    "res = []\n",
    "for img_mask in clusters:\n",
    "\n",
    "    img_cropped = cv2.bitwise_and(img_gray, img_gray, mask=img_mask)\n",
    "    non_zero_coords = cv2.findNonZero(img_mask)\n",
    "    box_cordinates = cv2.boundingRect(non_zero_coords)\n",
    "\n",
    "    # plt.imshow(img_cropped)\n",
    "\n",
    "    for angle in [0, -90, 90, 180]:\n",
    "        text = pytesseract.image_to_string(img_cropped, lang='rus', config='--psm 3')\n",
    "        text = speller.spelled(text)\n",
    "        is_correct = len(text)>0\n",
    "        text = text + '\\n'\n",
    "        if len(text) and is_correct:\n",
    "            res.append(RecognizeResult(text, angle, *box_cordinates))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [i.angle for i in res]\n",
    "general_angle = max(set(angles), key=angles.count)\n",
    "slope = 2\n",
    "metric = {\n",
    "    0: lambda f: f. x + slope * f.y,\n",
    "    -90: lambda f: slope * f.x - (f.y + f.dy),\n",
    "    90: lambda f: -slope * (f.x + f.dx) + f.y,\n",
    "    180: lambda f: -(f.x + f.dx) - slope * (f.y + f.dy),\n",
    "}[general_angle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Еврогрупп Общество с ограниченной ответственностью.\n",
      "\n",
      "«Торговая Компания «ЕвроГруп»\n",
      "ол сковороду Борская 17 ИННЛЕТИБ259 ООЧ2960\n",
      "огтниАЗеря , ОКЛОРРУНЕ ЛО «НБД-Банко г.Н- Новгороя,БИКОИ2202705\n",
      "озн за ЧООО ОО 050022557 Корусченуо 1014 О.00ООДООС\n",
      "\"Б-тай: счгостир$2@упай пуТелефонифанс: $ (831) 253-98-60,253-37-91\n",
      "\n",
      " № 364 от « 28» мая 2015 г\n",
      "\n",
      " ©ОО«СтройЮрист»\n",
      "\n",
      " В Строй!Орнсте мы оформляли сертификат 15О 9001 для участия в\n",
      "тендере. Нас сразу привлекла стоимость в 19 тысяч рублей. И прочность\n",
      "‘оформяения сертнфиката, та как срокн у нас «горелн». ЛЮ телефону\n",
      "получили грамотную консультацию по Т5 и ская документа был у ас в\n",
      "‘этот же день, В результате тендер мы выиграли н успещно работаем.\n",
      "Спасибо СтройЮрнся, за качественную работу?\n",
      "\n",
      "\n",
      " отзыВ\n",
      "\n",
      " С уважением,\n",
      "Директор.\n",
      "\n",
      "©0О «ТК Еврогру Белов Е.А\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([i.text for i in sorted(res, key=metric)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26c91141e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(img_gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
